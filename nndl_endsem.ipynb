{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fae2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0a8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up hyperparameters and device ---\n",
      "Using device: cuda:0\n",
      "\n",
      "--- Preparing CIFAR-10 dataset ---\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "--- Epoch 1/20 ---\n",
      "Epoch Summary | Loss: 1.7058 | Accuracy: 37.67%\n",
      "\n",
      "--- Epoch 2/20 ---\n",
      "Epoch Summary | Loss: 1.4588 | Accuracy: 46.56%\n",
      "\n",
      "--- Epoch 3/20 ---\n",
      "Epoch Summary | Loss: 1.3365 | Accuracy: 51.34%\n",
      "\n",
      "--- Epoch 4/20 ---\n",
      "Epoch Summary | Loss: 1.2391 | Accuracy: 55.37%\n",
      "\n",
      "--- Epoch 5/20 ---\n",
      "Epoch Summary | Loss: 1.1668 | Accuracy: 58.15%\n",
      "\n",
      "--- Epoch 6/20 ---\n",
      "Epoch Summary | Loss: 1.1141 | Accuracy: 60.24%\n",
      "\n",
      "--- Epoch 7/20 ---\n",
      "Epoch Summary | Loss: 1.0720 | Accuracy: 61.98%\n",
      "\n",
      "--- Epoch 8/20 ---\n",
      "Epoch Summary | Loss: 1.0389 | Accuracy: 63.40%\n",
      "\n",
      "--- Epoch 9/20 ---\n",
      "Epoch Summary | Loss: 1.0068 | Accuracy: 64.54%\n",
      "\n",
      "--- Epoch 10/20 ---\n",
      "Epoch Summary | Loss: 0.9756 | Accuracy: 65.43%\n",
      "\n",
      "--- Epoch 11/20 ---\n",
      "Epoch Summary | Loss: 0.9630 | Accuracy: 66.22%\n",
      "\n",
      "--- Epoch 12/20 ---\n",
      "Epoch Summary | Loss: 0.9340 | Accuracy: 67.42%\n",
      "\n",
      "--- Epoch 13/20 ---\n",
      "Epoch Summary | Loss: 0.9214 | Accuracy: 67.65%\n",
      "\n",
      "--- Epoch 14/20 ---\n",
      "Epoch Summary | Loss: 0.9011 | Accuracy: 68.46%\n",
      "\n",
      "--- Epoch 15/20 ---\n",
      "Epoch Summary | Loss: 0.8879 | Accuracy: 69.18%\n",
      "\n",
      "--- Epoch 16/20 ---\n",
      "Epoch Summary | Loss: 0.8662 | Accuracy: 69.72%\n",
      "\n",
      "--- Epoch 17/20 ---\n",
      "Epoch Summary | Loss: 0.8553 | Accuracy: 70.28%\n",
      "\n",
      "--- Epoch 18/20 ---\n",
      "Epoch Summary | Loss: 0.8462 | Accuracy: 70.71%\n",
      "\n",
      "--- Epoch 19/20 ---\n",
      "Epoch Summary | Loss: 0.8286 | Accuracy: 71.19%\n",
      "\n",
      "--- Epoch 20/20 ---\n",
      "Epoch Summary | Loss: 0.8137 | Accuracy: 71.70%\n",
      "\n",
      "--- Finished Training ---\n",
      "\n",
      "Test Loss: 0.7330 | Test Accuracy: 75.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7330012047767639, 75.17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# CUSTOM CNN on CIFAR-10 (PyTorch)\n",
    "# ======================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 1: SETUP AND HYPERPARAMETERS\n",
    "# ======================================================================\n",
    "print(\"--- Setting up hyperparameters and device ---\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 10           # CIFAR-10 has 10 classes\n",
    "IMAGE_SIZE = 64            # Resize from 32x32 → 64x64\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 2: DATA LOADING AND AUGMENTATION\n",
    "# ======================================================================\n",
    "print(\"\\n--- Preparing CIFAR-10 dataset ---\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomCrop(IMAGE_SIZE, padding=8),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 3: CUSTOM CNN MODEL DEFINITION\n",
    "# ======================================================================\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    \"\"\"Custom CNN architecture for CIFAR-10 (64x64).\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Block 1: Conv -> BN -> ReLU -> MaxPool\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Block 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Block 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 4: TRAINING AND EVALUATION FUNCTIONS\n",
    "# ======================================================================\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=10, device='cpu'):\n",
    "    \"\"\"Train a PyTorch model.\"\"\"\n",
    "    history = {'loss': [], 'acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "        for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = (correct_predictions / total_samples) * 100\n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['acc'].append(epoch_acc)\n",
    "        print(f\"Epoch Summary | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "    \n",
    "    print('\\n--- Finished Training ---')\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, testloader, criterion, device='cpu'):\n",
    "    \"\"\"Evaluate model performance on test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = running_loss / total_samples\n",
    "    test_acc = (correct_predictions / total_samples) * 100\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 5: TRAIN + EVALUATE PIPELINE\n",
    "# ======================================================================\n",
    "\n",
    "model = CustomCNN(num_classes=NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_history = train_model(model, trainloader, criterion, optimizer,\n",
    "                            epochs=EPOCHS, device=device)\n",
    "evaluate_model(model, testloader, criterion, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f641c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up hyperparameters and device ---\n",
      "Using device: cuda:0\n",
      "\n",
      "--- Preparing CIFAR-10 dataset ---\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "--- Initializing Model, Loss, and Optimizer ---\n",
      "Initializing ResNet-18 model with random weights.\n",
      "\n",
      "--- Training ResNet-18 from scratch ---\n",
      "\n",
      "--- Epoch 1/20 ---\n",
      "Epoch Summary | Loss: 1.5690 | Accuracy: 41.89%\n",
      "\n",
      "--- Epoch 2/20 ---\n",
      "Epoch Summary | Loss: 1.1133 | Accuracy: 59.83%\n",
      "\n",
      "--- Epoch 3/20 ---\n",
      "Epoch Summary | Loss: 0.8755 | Accuracy: 68.89%\n",
      "\n",
      "--- Epoch 4/20 ---\n",
      "Epoch Summary | Loss: 0.7295 | Accuracy: 74.25%\n",
      "\n",
      "--- Epoch 5/20 ---\n",
      "Epoch Summary | Loss: 0.6315 | Accuracy: 78.03%\n",
      "\n",
      "--- Epoch 6/20 ---\n",
      "Epoch Summary | Loss: 0.5598 | Accuracy: 80.40%\n",
      "\n",
      "--- Epoch 7/20 ---\n",
      "Epoch Summary | Loss: 0.5104 | Accuracy: 82.42%\n",
      "\n",
      "--- Epoch 8/20 ---\n",
      "Epoch Summary | Loss: 0.4638 | Accuracy: 83.85%\n",
      "\n",
      "--- Epoch 9/20 ---\n",
      "Epoch Summary | Loss: 0.4306 | Accuracy: 84.97%\n",
      "\n",
      "--- Epoch 10/20 ---\n",
      "Epoch Summary | Loss: 0.3996 | Accuracy: 86.00%\n",
      "\n",
      "--- Epoch 11/20 ---\n",
      "Epoch Summary | Loss: 0.3694 | Accuracy: 87.16%\n",
      "\n",
      "--- Epoch 12/20 ---\n",
      "Epoch Summary | Loss: 0.3476 | Accuracy: 87.95%\n",
      "\n",
      "--- Epoch 13/20 ---\n",
      "Epoch Summary | Loss: 0.3225 | Accuracy: 88.78%\n",
      "\n",
      "--- Epoch 14/20 ---\n",
      "Epoch Summary | Loss: 0.3086 | Accuracy: 89.11%\n",
      "\n",
      "--- Epoch 15/20 ---\n",
      "Epoch Summary | Loss: 0.2887 | Accuracy: 90.01%\n",
      "\n",
      "--- Epoch 16/20 ---\n",
      "Epoch Summary | Loss: 0.2001 | Accuracy: 93.21%\n",
      "\n",
      "--- Epoch 17/20 ---\n",
      "Epoch Summary | Loss: 0.1798 | Accuracy: 94.06%\n",
      "\n",
      "--- Epoch 18/20 ---\n",
      "Epoch Summary | Loss: 0.1697 | Accuracy: 94.29%\n",
      "\n",
      "--- Epoch 19/20 ---\n",
      "Epoch Summary | Loss: 0.1609 | Accuracy: 94.52%\n",
      "\n",
      "--- Epoch 20/20 ---\n",
      "Epoch Summary | Loss: 0.1567 | Accuracy: 94.73%\n",
      "\n",
      "--- Finished Training ---\n",
      "\n",
      "--- Evaluating model on the test set ---\n",
      "\n",
      "Final Test Results:\n",
      "Loss: 0.3157\n",
      "Accuracy: 89.97%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 1: SETUP AND HYPERPARAMETERS RESNET-18\n",
    "# ==============================================================================\n",
    "print(\"--- Setting up hyperparameters and device ---\")\n",
    "# Set the device to a GPU if available, otherwise use the CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define hyperparameters\n",
    "# NOTE: Training from scratch requires more epochs to converge.\n",
    "# 40-50 epochs is a good starting point.\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01 # Initial learning rate for SGD\n",
    "NUM_CLASSES = 10     # For CIFAR-10\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: DATA LOADING AND AUGMENTATION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Preparing CIFAR-10 dataset ---\")\n",
    "# Define data augmentation and normalization for the training set\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Define normalization for the test set (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Create the data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 3: MODEL AND HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def create_resnet18_from_scratch(num_classes=10):\n",
    "    \"\"\"\n",
    "    Creates a ResNet-18 model with random initial weights (trained from scratch).\n",
    "    \"\"\"\n",
    "    print(\"Initializing ResNet-18 model with random weights.\")\n",
    "    # Load a ResNet18 model with weights=None for random initialization\n",
    "    model = resnet18(weights=None, num_classes=num_classes)\n",
    "    \n",
    "    # --- MODIFICATION FOR CIFAR-10 ---\n",
    "    # To improve performance on small 32x32 images, it's highly recommended\n",
    "    # to make the first layer less aggressive.\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    # --- END OF MODIFICATION ---\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, scheduler=None, epochs=20, device='cpu'):\n",
    "    \"\"\"Function to train a PyTorch model.\"\"\"\n",
    "    history = {'loss': [], 'accuracy': []}\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = (correct_predictions / total_samples) * 100\n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['accuracy'].append(epoch_acc)\n",
    "        print(f\"Epoch Summary | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "    print('\\n--- Finished Training ---')\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, testloader, criterion, device='cpu'):\n",
    "    \"\"\"Function to evaluate a PyTorch model's performance.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    final_loss = running_loss / total_samples\n",
    "    final_acc = (correct_predictions / total_samples) * 100\n",
    "    return final_loss, final_acc\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 4: MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Initializing Model, Loss, and Optimizer ---\")\n",
    "# Create the model FROM SCRATCH and move it to the configured device\n",
    "model_from_scratch = create_resnet18_from_scratch(num_classes=NUM_CLASSES)\n",
    "model_from_scratch.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer to train ALL model parameters\n",
    "optimizer = optim.SGD(model_from_scratch.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=15, gamma=0.1) # Adjusted step_size for more epochs\n",
    "\n",
    "# --- Start Training ---\n",
    "print(\"\\n--- Training ResNet-18 from scratch ---\")\n",
    "history = train_model(model_from_scratch, trainloader, criterion, optimizer, scheduler=scheduler, epochs=EPOCHS, device=device)\n",
    "\n",
    "# --- Evaluate the Model ---\n",
    "print(\"\\n--- Evaluating model on the test set ---\")\n",
    "final_loss, final_acc = evaluate_model(model_from_scratch, testloader, criterion, device=device)\n",
    "\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"Loss: {final_loss:.4f}\")\n",
    "print(f\"Accuracy: {final_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb1a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/20]  Loss: 1.8204  Acc: 33.49%\n",
      "Epoch [2/20]  Loss: 1.5453  Acc: 44.08%\n",
      "Epoch [3/20]  Loss: 1.4516  Acc: 47.57%\n",
      "Epoch [4/20]  Loss: 1.3795  Acc: 50.30%\n",
      "Epoch [5/20]  Loss: 1.3394  Acc: 51.85%\n",
      "Epoch [6/20]  Loss: 1.2963  Acc: 53.24%\n",
      "Epoch [7/20]  Loss: 1.2628  Acc: 54.44%\n",
      "Epoch [8/20]  Loss: 1.2295  Acc: 55.86%\n",
      "Epoch [9/20]  Loss: 1.2013  Acc: 56.87%\n",
      "Epoch [10/20]  Loss: 1.1768  Acc: 57.95%\n",
      "Epoch [11/20]  Loss: 1.1523  Acc: 58.54%\n",
      "Epoch [12/20]  Loss: 1.1345  Acc: 59.31%\n",
      "Epoch [13/20]  Loss: 1.1144  Acc: 60.29%\n",
      "Epoch [14/20]  Loss: 1.1009  Acc: 60.58%\n",
      "Epoch [15/20]  Loss: 1.0804  Acc: 61.30%\n",
      "Epoch [16/20]  Loss: 1.0699  Acc: 61.82%\n",
      "Epoch [17/20]  Loss: 1.0501  Acc: 62.38%\n",
      "Epoch [18/20]  Loss: 1.0373  Acc: 63.11%\n",
      "Epoch [19/20]  Loss: 1.0274  Acc: 63.32%\n",
      "Epoch [20/20]  Loss: 1.0187  Acc: 63.62%\n",
      "\n",
      "--- Training complete ---\n",
      "\n",
      "Test Loss: 0.9674 | Test Accuracy: 66.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# LeNet-5 BASELINE MODEL (for CIFAR-10, from scratch, CUDA-ready)\n",
    "# ==============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 1: DEVICE SETUP\n",
    "# ==============================================================================\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: DATASET (CIFAR-10)\n",
    "# ==============================================================================\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 3: LENET MODEL DEFINITION\n",
    "# ==============================================================================\n",
    "\n",
    "class LeNetCIFAR10(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNetCIFAR10, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=2)  # 3x32x32 → 6x32x32\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)                 # 6x16x16\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)            # 16x12x12\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 4: TRAINING AND EVALUATION\n",
    "# ==============================================================================\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=10, device='cpu'):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]  Loss: {epoch_loss:.4f}  Acc: {epoch_acc:.2f}%\")\n",
    "\n",
    "    print(\"\\n--- Training complete ---\\n\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, testloader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {avg_loss:.4f} | Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 5: MODEL INITIALIZATION AND RUN\n",
    "# ==============================================================================\n",
    "\n",
    "model = LeNetCIFAR10(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 20\n",
    "train_model(model, trainloader, criterion, optimizer, epochs=EPOCHS, device=device)\n",
    "evaluate_model(model, testloader, criterion, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
