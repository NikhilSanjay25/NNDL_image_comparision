{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fae2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0a8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up hyperparameters and device ---\n",
      "Using device: cuda:0\n",
      "\n",
      "--- Preparing CIFAR-10 dataset ---\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "--- Epoch 1/20 ---\n",
      "Epoch Summary | Loss: 1.7058 | Accuracy: 37.67%\n",
      "\n",
      "--- Epoch 2/20 ---\n",
      "Epoch Summary | Loss: 1.4588 | Accuracy: 46.56%\n",
      "\n",
      "--- Epoch 3/20 ---\n",
      "Epoch Summary | Loss: 1.3365 | Accuracy: 51.34%\n",
      "\n",
      "--- Epoch 4/20 ---\n",
      "Epoch Summary | Loss: 1.2391 | Accuracy: 55.37%\n",
      "\n",
      "--- Epoch 5/20 ---\n",
      "Epoch Summary | Loss: 1.1668 | Accuracy: 58.15%\n",
      "\n",
      "--- Epoch 6/20 ---\n",
      "Epoch Summary | Loss: 1.1141 | Accuracy: 60.24%\n",
      "\n",
      "--- Epoch 7/20 ---\n",
      "Epoch Summary | Loss: 1.0720 | Accuracy: 61.98%\n",
      "\n",
      "--- Epoch 8/20 ---\n",
      "Epoch Summary | Loss: 1.0389 | Accuracy: 63.40%\n",
      "\n",
      "--- Epoch 9/20 ---\n",
      "Epoch Summary | Loss: 1.0068 | Accuracy: 64.54%\n",
      "\n",
      "--- Epoch 10/20 ---\n",
      "Epoch Summary | Loss: 0.9756 | Accuracy: 65.43%\n",
      "\n",
      "--- Epoch 11/20 ---\n",
      "Epoch Summary | Loss: 0.9630 | Accuracy: 66.22%\n",
      "\n",
      "--- Epoch 12/20 ---\n",
      "Epoch Summary | Loss: 0.9340 | Accuracy: 67.42%\n",
      "\n",
      "--- Epoch 13/20 ---\n",
      "Epoch Summary | Loss: 0.9214 | Accuracy: 67.65%\n",
      "\n",
      "--- Epoch 14/20 ---\n",
      "Epoch Summary | Loss: 0.9011 | Accuracy: 68.46%\n",
      "\n",
      "--- Epoch 15/20 ---\n",
      "Epoch Summary | Loss: 0.8879 | Accuracy: 69.18%\n",
      "\n",
      "--- Epoch 16/20 ---\n",
      "Epoch Summary | Loss: 0.8662 | Accuracy: 69.72%\n",
      "\n",
      "--- Epoch 17/20 ---\n",
      "Epoch Summary | Loss: 0.8553 | Accuracy: 70.28%\n",
      "\n",
      "--- Epoch 18/20 ---\n",
      "Epoch Summary | Loss: 0.8462 | Accuracy: 70.71%\n",
      "\n",
      "--- Epoch 19/20 ---\n",
      "Epoch Summary | Loss: 0.8286 | Accuracy: 71.19%\n",
      "\n",
      "--- Epoch 20/20 ---\n",
      "Epoch Summary | Loss: 0.8137 | Accuracy: 71.70%\n",
      "\n",
      "--- Finished Training ---\n",
      "\n",
      "Test Loss: 0.7330 | Test Accuracy: 75.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7330012047767639, 75.17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# CUSTOM CNN on CIFAR-10 (PyTorch)\n",
    "# ======================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 1: SETUP AND HYPERPARAMETERS\n",
    "# ======================================================================\n",
    "print(\"--- Setting up hyperparameters and device ---\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 10           # CIFAR-10 has 10 classes\n",
    "IMAGE_SIZE = 64            # Resize from 32x32 â†’ 64x64\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 2: DATA LOADING AND AUGMENTATION\n",
    "# ======================================================================\n",
    "print(\"\\n--- Preparing CIFAR-10 dataset ---\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomCrop(IMAGE_SIZE, padding=8),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 3: CUSTOM CNN MODEL DEFINITION\n",
    "# ======================================================================\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    \"\"\"Custom CNN architecture for CIFAR-10 (64x64).\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Block 1: Conv -> BN -> ReLU -> MaxPool\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Block 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Block 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 4: TRAINING AND EVALUATION FUNCTIONS\n",
    "# ======================================================================\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=10, device='cpu'):\n",
    "    \"\"\"Train a PyTorch model.\"\"\"\n",
    "    history = {'loss': [], 'acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "        for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = (correct_predictions / total_samples) * 100\n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['acc'].append(epoch_acc)\n",
    "        print(f\"Epoch Summary | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "    \n",
    "    print('\\n--- Finished Training ---')\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_model(model, testloader, criterion, device='cpu'):\n",
    "    \"\"\"Evaluate model performance on test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = running_loss / total_samples\n",
    "    test_acc = (correct_predictions / total_samples) * 100\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# ======================================================================\n",
    "# SECTION 5: TRAIN + EVALUATE PIPELINE\n",
    "# ======================================================================\n",
    "\n",
    "model = CustomCNN(num_classes=NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_history = train_model(model, trainloader, criterion, optimizer,\n",
    "                            epochs=EPOCHS, device=device)\n",
    "evaluate_model(model, testloader, criterion, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f641c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up hyperparameters and device ---\n",
      "Using device: cuda:0\n",
      "\n",
      "--- Preparing CIFAR-10 dataset ---\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "--- Initializing Model, Loss, and Optimizer ---\n",
      "Initializing ResNet-18 model with random weights.\n",
      "\n",
      "--- Training ResNet-18 from scratch ---\n",
      "\n",
      "--- Epoch 1/20 ---\n",
      "Epoch Summary | Loss: 1.5690 | Accuracy: 41.89%\n",
      "\n",
      "--- Epoch 2/20 ---\n",
      "Epoch Summary | Loss: 1.1133 | Accuracy: 59.83%\n",
      "\n",
      "--- Epoch 3/20 ---\n",
      "Epoch Summary | Loss: 0.8755 | Accuracy: 68.89%\n",
      "\n",
      "--- Epoch 4/20 ---\n",
      "Epoch Summary | Loss: 0.7295 | Accuracy: 74.25%\n",
      "\n",
      "--- Epoch 5/20 ---\n",
      "Epoch Summary | Loss: 0.6315 | Accuracy: 78.03%\n",
      "\n",
      "--- Epoch 6/20 ---\n",
      "Epoch Summary | Loss: 0.5598 | Accuracy: 80.40%\n",
      "\n",
      "--- Epoch 7/20 ---\n",
      "Epoch Summary | Loss: 0.5104 | Accuracy: 82.42%\n",
      "\n",
      "--- Epoch 8/20 ---\n",
      "Epoch Summary | Loss: 0.4638 | Accuracy: 83.85%\n",
      "\n",
      "--- Epoch 9/20 ---\n",
      "Epoch Summary | Loss: 0.4306 | Accuracy: 84.97%\n",
      "\n",
      "--- Epoch 10/20 ---\n",
      "Epoch Summary | Loss: 0.3996 | Accuracy: 86.00%\n",
      "\n",
      "--- Epoch 11/20 ---\n",
      "Epoch Summary | Loss: 0.3694 | Accuracy: 87.16%\n",
      "\n",
      "--- Epoch 12/20 ---\n",
      "Epoch Summary | Loss: 0.3476 | Accuracy: 87.95%\n",
      "\n",
      "--- Epoch 13/20 ---\n",
      "Epoch Summary | Loss: 0.3225 | Accuracy: 88.78%\n",
      "\n",
      "--- Epoch 14/20 ---\n",
      "Epoch Summary | Loss: 0.3086 | Accuracy: 89.11%\n",
      "\n",
      "--- Epoch 15/20 ---\n",
      "Epoch Summary | Loss: 0.2887 | Accuracy: 90.01%\n",
      "\n",
      "--- Epoch 16/20 ---\n",
      "Epoch Summary | Loss: 0.2001 | Accuracy: 93.21%\n",
      "\n",
      "--- Epoch 17/20 ---\n",
      "Epoch Summary | Loss: 0.1798 | Accuracy: 94.06%\n",
      "\n",
      "--- Epoch 18/20 ---\n",
      "Epoch Summary | Loss: 0.1697 | Accuracy: 94.29%\n",
      "\n",
      "--- Epoch 19/20 ---\n",
      "Epoch Summary | Loss: 0.1609 | Accuracy: 94.52%\n",
      "\n",
      "--- Epoch 20/20 ---\n",
      "Epoch Summary | Loss: 0.1567 | Accuracy: 94.73%\n",
      "\n",
      "--- Finished Training ---\n",
      "\n",
      "--- Evaluating model on the test set ---\n",
      "\n",
      "Final Test Results:\n",
      "Loss: 0.3157\n",
      "Accuracy: 89.97%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 1: SETUP AND HYPERPARAMETERS RESNET-18\n",
    "# ==============================================================================\n",
    "print(\"--- Setting up hyperparameters and device ---\")\n",
    "# Set the device to a GPU if available, otherwise use the CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define hyperparameters\n",
    "# NOTE: Training from scratch requires more epochs to converge.\n",
    "# 40-50 epochs is a good starting point.\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01 # Initial learning rate for SGD\n",
    "NUM_CLASSES = 10     # For CIFAR-10\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: DATA LOADING AND AUGMENTATION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Preparing CIFAR-10 dataset ---\")\n",
    "# Define data augmentation and normalization for the training set\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Define normalization for the test set (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Create the data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 3: MODEL AND HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def create_resnet18_from_scratch(num_classes=10):\n",
    "    \"\"\"\n",
    "    Creates a ResNet-18 model with random initial weights (trained from scratch).\n",
    "    \"\"\"\n",
    "    print(\"Initializing ResNet-18 model with random weights.\")\n",
    "    # Load a ResNet18 model with weights=None for random initialization\n",
    "    model = resnet18(weights=None, num_classes=num_classes)\n",
    "    \n",
    "    # --- MODIFICATION FOR CIFAR-10 ---\n",
    "    # To improve performance on small 32x32 images, it's highly recommended\n",
    "    # to make the first layer less aggressive.\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    # --- END OF MODIFICATION ---\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, scheduler=None, epochs=20, device='cpu'):\n",
    "    \"\"\"Function to train a PyTorch model.\"\"\"\n",
    "    history = {'loss': [], 'accuracy': []}\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = (correct_predictions / total_samples) * 100\n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['accuracy'].append(epoch_acc)\n",
    "        print(f\"Epoch Summary | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "    print('\\n--- Finished Training ---')\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, testloader, criterion, device='cpu'):\n",
    "    \"\"\"Function to evaluate a PyTorch model's performance.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    final_loss = running_loss / total_samples\n",
    "    final_acc = (correct_predictions / total_samples) * 100\n",
    "    return final_loss, final_acc\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 4: MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Initializing Model, Loss, and Optimizer ---\")\n",
    "# Create the model FROM SCRATCH and move it to the configured device\n",
    "model_from_scratch = create_resnet18_from_scratch(num_classes=NUM_CLASSES)\n",
    "model_from_scratch.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer to train ALL model parameters\n",
    "optimizer = optim.SGD(model_from_scratch.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=15, gamma=0.1) # Adjusted step_size for more epochs\n",
    "\n",
    "# --- Start Training ---\n",
    "print(\"\\n--- Training ResNet-18 from scratch ---\")\n",
    "history = train_model(model_from_scratch, trainloader, criterion, optimizer, scheduler=scheduler, epochs=EPOCHS, device=device)\n",
    "\n",
    "# --- Evaluate the Model ---\n",
    "print(\"\\n--- Evaluating model on the test set ---\")\n",
    "final_loss, final_acc = evaluate_model(model_from_scratch, testloader, criterion, device=device)\n",
    "\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"Loss: {final_loss:.4f}\")\n",
    "print(f\"Accuracy: {final_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be686075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/20] Train Loss: 1.5408 | Train Acc: 43.61% Test Loss: 1.2972 | Test Acc: 52.38%\n",
      "Epoch [2/20] Train Loss: 1.1596 | Train Acc: 58.54% Test Loss: 1.0406 | Test Acc: 63.38%\n",
      "Epoch [3/20] Train Loss: 0.9854 | Train Acc: 65.17% Test Loss: 0.9201 | Test Acc: 67.55%\n",
      "Epoch [4/20] Train Loss: 0.8713 | Train Acc: 69.31% Test Loss: 0.8659 | Test Acc: 69.28%\n",
      "Epoch [5/20] Train Loss: 0.7907 | Train Acc: 72.18% Test Loss: 0.8316 | Test Acc: 71.30%\n",
      "Epoch [6/20] Train Loss: 0.7395 | Train Acc: 73.92% Test Loss: 0.8089 | Test Acc: 72.71%\n",
      "Epoch [7/20] Train Loss: 0.6820 | Train Acc: 76.25% Test Loss: 0.7469 | Test Acc: 73.94%\n",
      "Epoch [8/20] Train Loss: 0.6471 | Train Acc: 77.10% Test Loss: 0.6893 | Test Acc: 76.22%\n",
      "Epoch [9/20] Train Loss: 0.6137 | Train Acc: 78.53% Test Loss: 0.7084 | Test Acc: 76.05%\n",
      "Epoch [10/20] Train Loss: 0.5823 | Train Acc: 79.77% Test Loss: 0.7492 | Test Acc: 74.47%\n",
      "Epoch [11/20] Train Loss: 0.5647 | Train Acc: 80.29% Test Loss: 0.6169 | Test Acc: 79.12%\n",
      "Epoch [12/20] Train Loss: 0.5367 | Train Acc: 81.28% Test Loss: 0.6714 | Test Acc: 76.80%\n",
      "Epoch [13/20] Train Loss: 0.5175 | Train Acc: 82.03% Test Loss: 0.6123 | Test Acc: 79.69%\n",
      "Epoch [14/20] Train Loss: 0.4960 | Train Acc: 82.98% Test Loss: 0.5700 | Test Acc: 80.80%\n",
      "Epoch [15/20] Train Loss: 0.4854 | Train Acc: 83.07% Test Loss: 0.5789 | Test Acc: 80.52%\n",
      "Epoch [16/20] Train Loss: 0.4627 | Train Acc: 83.87% Test Loss: 0.5534 | Test Acc: 81.00%\n",
      "Epoch [17/20] Train Loss: 0.4535 | Train Acc: 84.34% Test Loss: 0.5909 | Test Acc: 79.81%\n",
      "Epoch [18/20] Train Loss: 0.4416 | Train Acc: 84.71% Test Loss: 0.5378 | Test Acc: 81.84%\n",
      "Epoch [19/20] Train Loss: 0.4283 | Train Acc: 85.20% Test Loss: 0.5280 | Test Acc: 81.96%\n",
      "Epoch [20/20] Train Loss: 0.4137 | Train Acc: 85.53% Test Loss: 0.5080 | Test Acc: 82.91%\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# DenseNet-121 for CIFAR-10 - PyTorch\n",
    "# High accuracy setup with CUDA\n",
    "# =====================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ----------------- Check CUDA -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------- Data Augmentation ----------------\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# ----------------- Load CIFAR-10 --------------------\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "# ----------------- Load DenseNet-121 ----------------\n",
    "model = models.densenet121(weights=None)  # start from scratch\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 10)  # CIFAR-10 has 10 classes\n",
    "model = model.to(device)\n",
    "\n",
    "# ----------------- Loss & Optimizer -----------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# ----------------- Training Function ----------------\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "# ----------------- Testing Function -----------------\n",
    "def test(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "# ----------------- Main Training Loop ----------------\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
    "          f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57050878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/20] | Train Loss: 4.0218, Train Acc: 16.29% | Test Loss: 1.9460, Test Acc: 23.10%\n",
      "Epoch [2/20] | Train Loss: 1.8678, Train Acc: 29.53% | Test Loss: 1.7239, Test Acc: 35.29%\n",
      "Epoch [3/20] | Train Loss: 1.7325, Train Acc: 34.55% | Test Loss: 1.6168, Test Acc: 40.12%\n",
      "Epoch [4/20] | Train Loss: 1.6092, Train Acc: 40.59% | Test Loss: 1.5219, Test Acc: 44.18%\n",
      "Epoch [5/20] | Train Loss: 1.5083, Train Acc: 44.81% | Test Loss: 1.3691, Test Acc: 49.40%\n",
      "Epoch [6/20] | Train Loss: 1.4136, Train Acc: 48.63% | Test Loss: 1.2995, Test Acc: 52.85%\n",
      "Epoch [7/20] | Train Loss: 1.3212, Train Acc: 52.48% | Test Loss: 1.2197, Test Acc: 56.21%\n",
      "Epoch [8/20] | Train Loss: 1.2129, Train Acc: 56.44% | Test Loss: 1.0920, Test Acc: 61.17%\n",
      "Epoch [9/20] | Train Loss: 1.1304, Train Acc: 59.61% | Test Loss: 1.0420, Test Acc: 62.78%\n",
      "Epoch [10/20] | Train Loss: 1.0344, Train Acc: 63.36% | Test Loss: 1.0195, Test Acc: 65.07%\n",
      "Epoch [11/20] | Train Loss: 1.0073, Train Acc: 64.40% | Test Loss: 0.9488, Test Acc: 66.99%\n",
      "Epoch [12/20] | Train Loss: 0.9174, Train Acc: 67.79% | Test Loss: 0.8785, Test Acc: 69.62%\n",
      "Epoch [13/20] | Train Loss: 0.8401, Train Acc: 70.55% | Test Loss: 0.8206, Test Acc: 71.21%\n",
      "Epoch [14/20] | Train Loss: 0.7701, Train Acc: 72.96% | Test Loss: 0.7471, Test Acc: 73.88%\n",
      "Epoch [15/20] | Train Loss: 0.7169, Train Acc: 75.01% | Test Loss: 0.6962, Test Acc: 75.20%\n",
      "Epoch [16/20] | Train Loss: 0.6566, Train Acc: 77.03% | Test Loss: 0.6578, Test Acc: 77.15%\n",
      "Epoch [17/20] | Train Loss: 0.6049, Train Acc: 79.08% | Test Loss: 0.6220, Test Acc: 78.19%\n",
      "Epoch [18/20] | Train Loss: 0.5615, Train Acc: 80.59% | Test Loss: 0.5910, Test Acc: 79.42%\n",
      "Epoch [19/20] | Train Loss: 0.5273, Train Acc: 81.72% | Test Loss: 0.5778, Test Acc: 80.09%\n",
      "Epoch [20/20] | Train Loss: 0.5025, Train Acc: 82.50% | Test Loss: 0.5725, Test Acc: 80.54%\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# WideResNet for CIFAR-10 (PyTorch) - 20 Epochs\n",
    "# ======================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ---------------- Device -----------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------- Data Augmentation -----------------\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "# ---------------- WideResNet Definition -----------------\n",
    "# Using torchvision Wide_ResNet-28-10 pretrained on CIFAR\n",
    "from torchvision.models import wide_resnet50_2\n",
    "\n",
    "class CIFARWideResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CIFARWideResNet, self).__init__()\n",
    "        self.model = wide_resnet50_2(weights=None)  # train from scratch\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = CIFARWideResNet().to(device)\n",
    "\n",
    "# ---------------- Loss and Optimizer -----------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "\n",
    "# ---------------- Training Loop -----------------\n",
    "def train():\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# ---------------- Run Training -----------------\n",
    "for epoch in range(20):\n",
    "    train_loss, train_acc = train()\n",
    "    test_loss, test_acc = test()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/20] | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to ./torch_cache\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Train Loss: 1.1732 Train Acc: 59.18% Val Loss: 0.7862 Val Acc: 72.72%\n",
      "Epoch [2/20] Train Loss: 0.7584 Train Acc: 73.98% Val Loss: 0.6420 Val Acc: 77.14%\n",
      "Epoch [3/20] Train Loss: 0.6375 Train Acc: 78.08% Val Loss: 0.5666 Val Acc: 80.32%\n",
      "Epoch [4/20] Train Loss: 0.5616 Train Acc: 80.66% Val Loss: 0.5223 Val Acc: 82.32%\n",
      "Epoch [5/20] Train Loss: 0.5176 Train Acc: 82.24% Val Loss: 0.5236 Val Acc: 82.30%\n",
      "Epoch [6/20] Train Loss: 0.4811 Train Acc: 83.31% Val Loss: 0.4957 Val Acc: 83.42%\n",
      "Epoch [7/20] Train Loss: 0.4485 Train Acc: 84.48% Val Loss: 0.5072 Val Acc: 83.74%\n",
      "Epoch [8/20] Train Loss: 0.4223 Train Acc: 85.36% Val Loss: 0.4748 Val Acc: 83.88%\n",
      "Epoch [9/20] Train Loss: 0.4025 Train Acc: 86.20% Val Loss: 0.4625 Val Acc: 84.02%\n",
      "Epoch [10/20] Train Loss: 0.3856 Train Acc: 86.69% Val Loss: 0.4547 Val Acc: 84.38%\n",
      "Epoch [11/20] Train Loss: 0.3582 Train Acc: 87.61% Val Loss: 0.4382 Val Acc: 85.40%\n",
      "Epoch [12/20] Train Loss: 0.3431 Train Acc: 88.05% Val Loss: 0.4461 Val Acc: 85.48%\n",
      "Epoch [13/20] Train Loss: 0.3362 Train Acc: 88.45% Val Loss: 0.4461 Val Acc: 85.56%\n",
      "Epoch [14/20] Train Loss: 0.3217 Train Acc: 88.91% Val Loss: 0.4381 Val Acc: 85.46%\n",
      "Epoch [15/20] Train Loss: 0.2989 Train Acc: 89.71% Val Loss: 0.4448 Val Acc: 85.92%\n",
      "Epoch [16/20] Train Loss: 0.2981 Train Acc: 89.71% Val Loss: 0.4298 Val Acc: 86.20%\n",
      "Epoch [17/20] Train Loss: 0.2773 Train Acc: 90.39% Val Loss: 0.4182 Val Acc: 86.38%\n",
      "Epoch [18/20] Train Loss: 0.2678 Train Acc: 90.74% Val Loss: 0.4147 Val Acc: 86.66%\n",
      "Epoch [19/20] Train Loss: 0.2555 Train Acc: 91.11% Val Loss: 0.4402 Val Acc: 86.12%\n",
      "Epoch [20/20] Train Loss: 0.2425 Train Acc: 91.41% Val Loss: 0.4197 Val Acc: 86.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_21116\\3622515845.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{model_name}_best.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# EfficientNet-B0/B1 on CIFAR-10 with CUDA (PyTorch)\n",
    "# =====================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# ---------------- Device -----------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------- Hyperparameters -----------------\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 20\n",
    "model_name = \"efficientnet_b0\"  # Change to \"efficientnet_b1\" for B1\n",
    "\n",
    "# ---------------- Data Transforms -----------------\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# ---------------- CIFAR-10 Dataset -----------------\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Split train into train+val\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_set, val_set = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# ---------------- Load Model -----------------\n",
    "if model_name == \"efficientnet_b0\":\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "elif model_name == \"efficientnet_b1\":\n",
    "    model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
    "else:\n",
    "    raise ValueError(\"Choose model_name as 'efficientnet_b0' or 'efficientnet_b1'\")\n",
    "\n",
    "# Change the classifier for CIFAR-10 (10 classes)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "# ---------------- Loss & Optimizer -----------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# ---------------- Training Loop -----------------\n",
    "best_val_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = 100. * correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = 100. * correct / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), f\"{model_name}_best.pth\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}% \"\n",
    "          f\"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# ---------------- Test Accuracy -----------------\n",
    "model.load_state_dict(torch.load(f\"{model_name}_best.pth\"))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100.*correct/total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
