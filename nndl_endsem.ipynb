{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fae2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0a8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training CNN from Scratch ---\n",
      "Epoch 1/10 | Time: 14.58s | Loss: 1.5530 | Acc: 43.35% | Val Loss: 1.1924 | Val Acc: 56.94%\n",
      "Epoch 2/10 | Time: 18.09s | Loss: 1.1701 | Acc: 58.67% | Val Loss: 0.9497 | Val Acc: 66.19%\n",
      "Epoch 3/10 | Time: 16.48s | Loss: 1.0043 | Acc: 64.84% | Val Loss: 0.8740 | Val Acc: 69.34%\n",
      "Epoch 4/10 | Time: 13.70s | Loss: 0.8889 | Acc: 69.26% | Val Loss: 0.8280 | Val Acc: 71.11%\n",
      "Epoch 5/10 | Time: 11.36s | Loss: 0.8048 | Acc: 72.10% | Val Loss: 0.7675 | Val Acc: 73.91%\n",
      "Epoch 6/10 | Time: 19.18s | Loss: 0.7378 | Acc: 74.16% | Val Loss: 0.7692 | Val Acc: 74.14%\n",
      "Epoch 7/10 | Time: 13.63s | Loss: 0.6863 | Acc: 76.07% | Val Loss: 0.7541 | Val Acc: 75.10%\n",
      "Epoch 8/10 | Time: 15.05s | Loss: 0.6345 | Acc: 77.55% | Val Loss: 0.7470 | Val Acc: 74.92%\n",
      "Epoch 9/10 | Time: 16.52s | Loss: 0.5926 | Acc: 79.23% | Val Loss: 0.7142 | Val Acc: 75.91%\n",
      "Epoch 10/10 | Time: 15.25s | Loss: 0.5555 | Acc: 80.43% | Val Loss: 0.7566 | Val Acc: 75.35%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- CNN from Scratch ---\n",
    "print(\"\\n--- Training CNN from Scratch ---\")\n",
    "cnn_model = CustomCNN()\n",
    "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)\n",
    "history_cnn = train_model(cnn_model, trainloader, criterion, optimizer_cnn, epochs=EPOCHS)\n",
    "final_loss_cnn, final_acc_cnn = evaluate_model(cnn_model, testloader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f641c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up hyperparameters and device ---\n",
      "Using device: cuda:0\n",
      "\n",
      "--- Preparing CIFAR-10 dataset ---\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "--- Initializing Model, Loss, and Optimizer ---\n",
      "Initializing ResNet-18 model with random weights.\n",
      "\n",
      "--- Training ResNet-18 from scratch ---\n",
      "\n",
      "--- Epoch 1/40 ---\n",
      "Epoch Summary | Loss: 1.5426 | Accuracy: 43.01%\n",
      "\n",
      "--- Epoch 2/40 ---\n",
      "Epoch Summary | Loss: 1.1003 | Accuracy: 60.48%\n",
      "\n",
      "--- Epoch 3/40 ---\n",
      "Epoch Summary | Loss: 0.8588 | Accuracy: 69.54%\n",
      "\n",
      "--- Epoch 4/40 ---\n",
      "Epoch Summary | Loss: 0.7161 | Accuracy: 75.09%\n",
      "\n",
      "--- Epoch 5/40 ---\n",
      "Epoch Summary | Loss: 0.6250 | Accuracy: 78.16%\n",
      "\n",
      "--- Epoch 6/40 ---\n",
      "Epoch Summary | Loss: 0.5647 | Accuracy: 80.39%\n",
      "\n",
      "--- Epoch 7/40 ---\n",
      "Epoch Summary | Loss: 0.5124 | Accuracy: 82.37%\n",
      "\n",
      "--- Epoch 8/40 ---\n",
      "Epoch Summary | Loss: 0.4658 | Accuracy: 83.81%\n",
      "\n",
      "--- Epoch 9/40 ---\n",
      "Epoch Summary | Loss: 0.4323 | Accuracy: 85.02%\n",
      "\n",
      "--- Epoch 10/40 ---\n",
      "Epoch Summary | Loss: 0.4018 | Accuracy: 85.94%\n",
      "\n",
      "--- Epoch 11/40 ---\n",
      "Epoch Summary | Loss: 0.3714 | Accuracy: 87.08%\n",
      "\n",
      "--- Epoch 12/40 ---\n",
      "Epoch Summary | Loss: 0.3458 | Accuracy: 88.12%\n",
      "\n",
      "--- Epoch 13/40 ---\n",
      "Epoch Summary | Loss: 0.3275 | Accuracy: 88.62%\n",
      "\n",
      "--- Epoch 14/40 ---\n",
      "Epoch Summary | Loss: 0.3065 | Accuracy: 89.26%\n",
      "\n",
      "--- Epoch 15/40 ---\n",
      "Epoch Summary | Loss: 0.2927 | Accuracy: 89.66%\n",
      "\n",
      "--- Epoch 16/40 ---\n",
      "Epoch Summary | Loss: 0.2013 | Accuracy: 93.16%\n",
      "\n",
      "--- Epoch 17/40 ---\n",
      "Epoch Summary | Loss: 0.1763 | Accuracy: 94.10%\n",
      "\n",
      "--- Epoch 18/40 ---\n",
      "Epoch Summary | Loss: 0.1675 | Accuracy: 94.42%\n",
      "\n",
      "--- Epoch 19/40 ---\n",
      "Epoch Summary | Loss: 0.1613 | Accuracy: 94.49%\n",
      "\n",
      "--- Epoch 20/40 ---\n",
      "Epoch Summary | Loss: 0.1541 | Accuracy: 94.85%\n",
      "\n",
      "--- Epoch 21/40 ---\n",
      "Epoch Summary | Loss: 0.1466 | Accuracy: 95.18%\n",
      "\n",
      "--- Epoch 22/40 ---\n",
      "Epoch Summary | Loss: 0.1445 | Accuracy: 95.12%\n",
      "\n",
      "--- Epoch 23/40 ---\n",
      "Epoch Summary | Loss: 0.1393 | Accuracy: 95.28%\n",
      "\n",
      "--- Epoch 24/40 ---\n",
      "Epoch Summary | Loss: 0.1352 | Accuracy: 95.50%\n",
      "\n",
      "--- Epoch 25/40 ---\n",
      "Epoch Summary | Loss: 0.1297 | Accuracy: 95.66%\n",
      "\n",
      "--- Epoch 26/40 ---\n",
      "Epoch Summary | Loss: 0.1269 | Accuracy: 95.75%\n",
      "\n",
      "--- Epoch 27/40 ---\n",
      "Epoch Summary | Loss: 0.1228 | Accuracy: 95.77%\n",
      "\n",
      "--- Epoch 28/40 ---\n",
      "Epoch Summary | Loss: 0.1186 | Accuracy: 96.02%\n",
      "\n",
      "--- Epoch 29/40 ---\n",
      "Epoch Summary | Loss: 0.1161 | Accuracy: 96.09%\n",
      "\n",
      "--- Epoch 30/40 ---\n",
      "Epoch Summary | Loss: 0.1122 | Accuracy: 96.23%\n",
      "\n",
      "--- Epoch 31/40 ---\n",
      "Epoch Summary | Loss: 0.1029 | Accuracy: 96.59%\n",
      "\n",
      "--- Epoch 32/40 ---\n",
      "Epoch Summary | Loss: 0.1014 | Accuracy: 96.67%\n",
      "\n",
      "--- Epoch 33/40 ---\n",
      "Epoch Summary | Loss: 0.0988 | Accuracy: 96.80%\n",
      "\n",
      "--- Epoch 34/40 ---\n",
      "Epoch Summary | Loss: 0.0986 | Accuracy: 96.76%\n",
      "\n",
      "--- Epoch 35/40 ---\n",
      "Epoch Summary | Loss: 0.0997 | Accuracy: 96.74%\n",
      "\n",
      "--- Epoch 36/40 ---\n",
      "Epoch Summary | Loss: 0.0993 | Accuracy: 96.69%\n",
      "\n",
      "--- Epoch 37/40 ---\n",
      "Epoch Summary | Loss: 0.0974 | Accuracy: 96.82%\n",
      "\n",
      "--- Epoch 38/40 ---\n",
      "Epoch Summary | Loss: 0.0975 | Accuracy: 96.76%\n",
      "\n",
      "--- Epoch 39/40 ---\n",
      "Epoch Summary | Loss: 0.0979 | Accuracy: 96.77%\n",
      "\n",
      "--- Epoch 40/40 ---\n",
      "Epoch Summary | Loss: 0.0970 | Accuracy: 96.85%\n",
      "\n",
      "--- Finished Training ---\n",
      "\n",
      "--- Evaluating model on the test set ---\n",
      "\n",
      "Final Test Results:\n",
      "Loss: 0.3152\n",
      "Accuracy: 90.65%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 1: SETUP AND HYPERPARAMETERS RESNET-18\n",
    "# ==============================================================================\n",
    "print(\"--- Setting up hyperparameters and device ---\")\n",
    "# Set the device to a GPU if available, otherwise use the CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define hyperparameters\n",
    "# NOTE: Training from scratch requires more epochs to converge.\n",
    "# 40-50 epochs is a good starting point.\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01 # Initial learning rate for SGD\n",
    "NUM_CLASSES = 10     # For CIFAR-10\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: DATA LOADING AND AUGMENTATION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Preparing CIFAR-10 dataset ---\")\n",
    "# Define data augmentation and normalization for the training set\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Define normalization for the test set (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Create the data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 3: MODEL AND HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def create_resnet18_from_scratch(num_classes=10):\n",
    "    \"\"\"\n",
    "    Creates a ResNet-18 model with random initial weights (trained from scratch).\n",
    "    \"\"\"\n",
    "    print(\"Initializing ResNet-18 model with random weights.\")\n",
    "    # Load a ResNet18 model with weights=None for random initialization\n",
    "    model = resnet18(weights=None, num_classes=num_classes)\n",
    "    \n",
    "    # --- MODIFICATION FOR CIFAR-10 ---\n",
    "    # To improve performance on small 32x32 images, it's highly recommended\n",
    "    # to make the first layer less aggressive.\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    # --- END OF MODIFICATION ---\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, scheduler=None, epochs=20, device='cpu'):\n",
    "    \"\"\"Function to train a PyTorch model.\"\"\"\n",
    "    history = {'loss': [], 'accuracy': []}\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = (correct_predictions / total_samples) * 100\n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['accuracy'].append(epoch_acc)\n",
    "        print(f\"Epoch Summary | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "    print('\\n--- Finished Training ---')\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, testloader, criterion, device='cpu'):\n",
    "    \"\"\"Function to evaluate a PyTorch model's performance.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    final_loss = running_loss / total_samples\n",
    "    final_acc = (correct_predictions / total_samples) * 100\n",
    "    return final_loss, final_acc\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 4: MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Initializing Model, Loss, and Optimizer ---\")\n",
    "# Create the model FROM SCRATCH and move it to the configured device\n",
    "model_from_scratch = create_resnet18_from_scratch(num_classes=NUM_CLASSES)\n",
    "model_from_scratch.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer to train ALL model parameters\n",
    "optimizer = optim.SGD(model_from_scratch.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=15, gamma=0.1) # Adjusted step_size for more epochs\n",
    "\n",
    "# --- Start Training ---\n",
    "print(\"\\n--- Training ResNet-18 from scratch ---\")\n",
    "history = train_model(model_from_scratch, trainloader, criterion, optimizer, scheduler=scheduler, epochs=EPOCHS, device=device)\n",
    "\n",
    "# --- Evaluate the Model ---\n",
    "print(\"\\n--- Evaluating model on the test set ---\")\n",
    "final_loss, final_acc = evaluate_model(model_from_scratch, testloader, criterion, device=device)\n",
    "\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"Loss: {final_loss:.4f}\")\n",
    "print(f\"Accuracy: {final_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up hyperparameters and device ---\n",
      "Using device: cuda:0\n",
      "\n",
      "--- Preparing CIFAR-10 dataset ---\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "--- Initializing VGG-16 Model for Fine-Tuning ---\n",
      "\n",
      "--- Fine-Tuning the Full VGG-16 Model ---\n",
      "\n",
      "--- Epoch 1/20 ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 1: SETUP AND HYPERPARAMETERS\n",
    "# ==============================================================================\n",
    "print(\"--- Setting up hyperparameters and device ---\")\n",
    "# Set the device to a GPU if available, otherwise use the CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define hyperparameters\n",
    "EPOCHS = 20  # Epochs for fine-tuning the full model\n",
    "BATCH_SIZE = 128\n",
    "# Use a very low learning rate for fine-tuning the entire network\n",
    "LEARNING_RATE_FINETUNE = 0.0001 \n",
    "NUM_CLASSES = 10                  # For CIFAR-10\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: DATA LOADING AND AUGMENTATION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Preparing CIFAR-10 dataset ---\")\n",
    "# VGG models work best with larger images, so we resize CIFAR-10.\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "# Define data augmentation and normalization for the training set\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomCrop(IMAGE_SIZE, padding=8),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Define normalization for the test set (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Create the data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 3: MODEL AND HELPER FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def create_vgg16_finetune_model(num_classes=10):\n",
    "    \"\"\"Creates a pre-trained VGG-16 model where ALL layers are trainable.\"\"\"\n",
    "    # Load a pre-trained VGG-16 model\n",
    "    model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # NOTE: The layer freezing loop is removed. \n",
    "    # All layers (features and classifier) will be trainable.\n",
    "        \n",
    "    # Replace the final layer of the classifier\n",
    "    num_ftrs = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=10, device='cpu'):\n",
    "    \"\"\"Function to train a PyTorch model.\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{epochs} ---\")\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = (correct_predictions / total_samples) * 100\n",
    "        print(f\"Epoch Summary | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "    print('\\n--- Finished Training ---')\n",
    "\n",
    "def evaluate_model(model, testloader, criterion, device='cpu'):\n",
    "    \"\"\"Function to evaluate a PyTorch model's performance.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    final_loss = running_loss / total_samples\n",
    "    final_acc = (correct_predictions / total_samples) * 100\n",
    "    print(f\"\\nFinal Test Results | Loss: {final_loss:.4f} | Accuracy: {final_acc:.2f}%\")\n",
    "    return final_loss, final_acc\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 4: MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Initializing VGG-16 Model for Fine-Tuning ---\")\n",
    "# Create the VGG-16 model with all layers trainable\n",
    "finetune_model = create_vgg16_finetune_model(num_classes=NUM_CLASSES)\n",
    "finetune_model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer to train ALL parameters of the model\n",
    "optimizer = optim.Adam(finetune_model.parameters(), lr=LEARNING_RATE_FINETUNE)\n",
    "\n",
    "# --- Start Training ---\n",
    "print(\"\\n--- Fine-Tuning the Full VGG-16 Model ---\")\n",
    "train_model(finetune_model, trainloader, criterion, optimizer, epochs=EPOCHS, device=device)\n",
    "\n",
    "# --- Evaluate the Model ---\n",
    "print(\"\\n--- Evaluating fine-tuned VGG-16 model on the test set ---\")\n",
    "evaluate_model(finetune_model, testloader, criterion, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
