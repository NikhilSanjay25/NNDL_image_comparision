{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc39a65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# ------------------------------------------------------------\n",
    "# 2. Data transforms and loaders\n",
    "# ------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, \n",
    "                                 transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, \n",
    "                                transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b673b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "BasicCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Epoch [1/10] | Loss: 1.6718 | Train Acc: 38.61%\n",
      "Epoch [2/10] | Loss: 1.3640 | Train Acc: 50.54%\n",
      "Epoch [3/10] | Loss: 1.2535 | Train Acc: 55.00%\n",
      "Epoch [4/10] | Loss: 1.1914 | Train Acc: 57.68%\n",
      "Epoch [5/10] | Loss: 1.1518 | Train Acc: 59.16%\n",
      "Epoch [6/10] | Loss: 1.1341 | Train Acc: 59.80%\n",
      "Epoch [7/10] | Loss: 1.1061 | Train Acc: 61.00%\n",
      "Epoch [8/10] | Loss: 1.0873 | Train Acc: 61.90%\n",
      "Epoch [9/10] | Loss: 1.0704 | Train Acc: 62.27%\n",
      "Epoch [10/10] | Loss: 1.0539 | Train Acc: 62.86%\n",
      "\n",
      "✅ Test Accuracy: 68.46%\n",
      "⏱ Total Training Time: 1.87 mins\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Basic CNN on CIFAR-10 (PyTorch + CUDA)\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Check device (GPU/CPU)\n",
    "# ------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Data transforms and loaders\n",
    "# ------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, \n",
    "                                 transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, \n",
    "                                transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Define CNN model\n",
    "# ------------------------------------------------------------\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = BasicCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a30329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_MoreConv(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10] | Loss: 1.6427 | Train Acc: 39.84%\n",
      "Epoch [2/10] | Loss: 1.2825 | Train Acc: 53.74%\n",
      "Epoch [3/10] | Loss: 1.1295 | Train Acc: 59.64%\n",
      "Epoch [4/10] | Loss: 1.0489 | Train Acc: 63.30%\n",
      "Epoch [5/10] | Loss: 0.9927 | Train Acc: 65.24%\n",
      "Epoch [6/10] | Loss: 0.9507 | Train Acc: 66.60%\n",
      "Epoch [7/10] | Loss: 0.9165 | Train Acc: 68.01%\n",
      "Epoch [8/10] | Loss: 0.8901 | Train Acc: 68.78%\n",
      "Epoch [9/10] | Loss: 0.8669 | Train Acc: 69.80%\n",
      "Epoch [10/10] | Loss: 0.8493 | Train Acc: 70.32%\n",
      "\n",
      "✅ Test Accuracy: 73.90%\n",
      "⏱ Total Training Time: 2.74 mins\n"
     ]
    }
   ],
   "source": [
    "#One More Convolutional Layer\n",
    "class CNN_MoreConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MoreConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)  # one extra pool halves the size\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_MoreConv().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dc1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LessConv(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10] | Loss: 1.7926 | Train Acc: 34.00%\n",
      "Epoch [2/10] | Loss: 1.6005 | Train Acc: 41.48%\n",
      "Epoch [3/10] | Loss: 1.5353 | Train Acc: 43.79%\n",
      "Epoch [4/10] | Loss: 1.4980 | Train Acc: 45.68%\n",
      "Epoch [5/10] | Loss: 1.4685 | Train Acc: 46.88%\n",
      "Epoch [6/10] | Loss: 1.4400 | Train Acc: 47.78%\n",
      "Epoch [7/10] | Loss: 1.4198 | Train Acc: 48.72%\n",
      "Epoch [8/10] | Loss: 1.4059 | Train Acc: 49.56%\n",
      "Epoch [9/10] | Loss: 1.3871 | Train Acc: 49.89%\n",
      "Epoch [10/10] | Loss: 1.3811 | Train Acc: 50.45%\n",
      "\n",
      "✅ Test Accuracy: 58.64%\n",
      "⏱ Total Training Time: 2.11 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_LessConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LessConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN_LessConv().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb86ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_BiggerKernel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10] | Loss: 1.6806 | Train Acc: 38.46%\n",
      "Epoch [2/10] | Loss: 1.4098 | Train Acc: 48.94%\n",
      "Epoch [3/10] | Loss: 1.3084 | Train Acc: 53.20%\n",
      "Epoch [4/10] | Loss: 1.2491 | Train Acc: 55.18%\n",
      "Epoch [5/10] | Loss: 1.2076 | Train Acc: 56.90%\n",
      "Epoch [6/10] | Loss: 1.1726 | Train Acc: 58.24%\n",
      "Epoch [7/10] | Loss: 1.1503 | Train Acc: 59.23%\n",
      "Epoch [8/10] | Loss: 1.1349 | Train Acc: 59.99%\n",
      "Epoch [9/10] | Loss: 1.1213 | Train Acc: 60.36%\n",
      "Epoch [10/10] | Loss: 1.0986 | Train Acc: 61.18%\n",
      "\n",
      "✅ Test Accuracy: 65.68%\n",
      "⏱ Total Training Time: 2.84 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_BiggerKernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_BiggerKernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_BiggerKernel().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cca05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_NoDropout(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10] | Loss: 1.5624 | Train Acc: 43.47%\n",
      "Epoch [2/10] | Loss: 1.2031 | Train Acc: 56.79%\n",
      "Epoch [3/10] | Loss: 1.0635 | Train Acc: 61.99%\n",
      "Epoch [4/10] | Loss: 0.9812 | Train Acc: 65.16%\n",
      "Epoch [5/10] | Loss: 0.9246 | Train Acc: 67.09%\n",
      "Epoch [6/10] | Loss: 0.8818 | Train Acc: 68.64%\n",
      "Epoch [7/10] | Loss: 0.8460 | Train Acc: 70.18%\n",
      "Epoch [8/10] | Loss: 0.8147 | Train Acc: 71.36%\n",
      "Epoch [9/10] | Loss: 0.7858 | Train Acc: 72.46%\n",
      "Epoch [10/10] | Loss: 0.7644 | Train Acc: 73.25%\n",
      "\n",
      "✅ Test Accuracy: 71.74%\n",
      "⏱ Total Training Time: 1.99 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_NoDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_NoDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_NoDropout().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_AvgPool(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10] | Loss: 1.6589 | Train Acc: 39.45%\n",
      "Epoch [2/10] | Loss: 1.3749 | Train Acc: 49.96%\n",
      "Epoch [3/10] | Loss: 1.2626 | Train Acc: 54.79%\n",
      "Epoch [4/10] | Loss: 1.2012 | Train Acc: 57.18%\n",
      "Epoch [5/10] | Loss: 1.1540 | Train Acc: 59.05%\n",
      "Epoch [6/10] | Loss: 1.1173 | Train Acc: 60.31%\n",
      "Epoch [7/10] | Loss: 1.0952 | Train Acc: 61.15%\n",
      "Epoch [8/10] | Loss: 1.0701 | Train Acc: 62.31%\n",
      "Epoch [9/10] | Loss: 1.0495 | Train Acc: 62.80%\n",
      "Epoch [10/10] | Loss: 1.0298 | Train Acc: 63.64%\n",
      "\n",
      "✅ Test Accuracy: 68.80%\n",
      "⏱ Total Training Time: 1.96 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_AvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_AvgPool, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AvgPool2d(2, 2)  # changed pooling\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_AvgPool().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3857e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_MorePooling(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/10] | Loss: 1.6821 | Train Acc: 38.12%\n",
      "Epoch [2/10] | Loss: 1.4183 | Train Acc: 48.30%\n",
      "Epoch [3/10] | Loss: 1.3049 | Train Acc: 52.86%\n",
      "Epoch [4/10] | Loss: 1.2253 | Train Acc: 56.05%\n",
      "Epoch [5/10] | Loss: 1.1732 | Train Acc: 58.17%\n",
      "Epoch [6/10] | Loss: 1.1359 | Train Acc: 59.58%\n",
      "Epoch [7/10] | Loss: 1.1083 | Train Acc: 60.83%\n",
      "Epoch [8/10] | Loss: 1.0833 | Train Acc: 61.76%\n",
      "Epoch [9/10] | Loss: 1.0586 | Train Acc: 62.67%\n",
      "Epoch [10/10] | Loss: 1.0433 | Train Acc: 63.25%\n",
      "\n",
      "✅ Test Accuracy: 68.27%\n",
      "⏱ Total Training Time: 1.64 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_MorePooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MorePooling, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # smaller spatial size after extra pooling\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # first pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))   # second pooling\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_MorePooling().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
