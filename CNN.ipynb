{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc39a65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# ------------------------------------------------------------\n",
    "# 2. Data transforms and loaders\n",
    "# ------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, \n",
    "                                 transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, \n",
    "                                transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b673b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "BasicCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Epoch [1/20] | Loss: 1.6629 | Train Acc: 39.22%\n",
      "Epoch [2/20] | Loss: 1.3505 | Train Acc: 50.84%\n",
      "Epoch [3/20] | Loss: 1.2128 | Train Acc: 56.64%\n",
      "Epoch [4/20] | Loss: 1.1372 | Train Acc: 59.74%\n",
      "Epoch [5/20] | Loss: 1.0961 | Train Acc: 61.14%\n",
      "Epoch [6/20] | Loss: 1.0551 | Train Acc: 62.70%\n",
      "Epoch [7/20] | Loss: 1.0247 | Train Acc: 63.77%\n",
      "Epoch [8/20] | Loss: 0.9961 | Train Acc: 64.95%\n",
      "Epoch [9/20] | Loss: 0.9761 | Train Acc: 65.99%\n",
      "Epoch [10/20] | Loss: 0.9594 | Train Acc: 66.31%\n",
      "Epoch [11/20] | Loss: 0.9419 | Train Acc: 67.28%\n",
      "Epoch [12/20] | Loss: 0.9288 | Train Acc: 67.57%\n",
      "Epoch [13/20] | Loss: 0.9130 | Train Acc: 68.22%\n",
      "Epoch [14/20] | Loss: 0.8997 | Train Acc: 68.66%\n",
      "Epoch [15/20] | Loss: 0.8871 | Train Acc: 69.13%\n",
      "Epoch [16/20] | Loss: 0.8760 | Train Acc: 69.40%\n",
      "Epoch [17/20] | Loss: 0.8707 | Train Acc: 69.54%\n",
      "Epoch [18/20] | Loss: 0.8580 | Train Acc: 70.05%\n",
      "Epoch [19/20] | Loss: 0.8464 | Train Acc: 70.61%\n",
      "Epoch [20/20] | Loss: 0.8448 | Train Acc: 70.66%\n",
      "\n",
      "✅ Test Accuracy: 73.00%\n",
      "⏱ Total Training Time: 3.88 mins\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Basic CNN on CIFAR-10 (PyTorch + CUDA)\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Check device (GPU/CPU)\n",
    "# ------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Data transforms and loaders\n",
    "# ------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, \n",
    "                                 transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, \n",
    "                                transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Define CNN model\n",
    "# ------------------------------------------------------------\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply pooling after the first convolution block\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # Apply pooling after the second convolution block\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the tensor. The input shape is now correctly (batch_size, 64, 8, 8)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        \n",
    "        # Apply activation and dropout after the first fully-connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final output layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = BasicCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a30329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_MoreConv(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/20] | Loss: 1.6600 | Train Acc: 39.00%\n",
      "Epoch [2/20] | Loss: 1.3109 | Train Acc: 52.83%\n",
      "Epoch [3/20] | Loss: 1.1571 | Train Acc: 58.94%\n",
      "Epoch [4/20] | Loss: 1.0698 | Train Acc: 62.23%\n",
      "Epoch [5/20] | Loss: 1.0120 | Train Acc: 64.35%\n",
      "Epoch [6/20] | Loss: 0.9697 | Train Acc: 66.07%\n",
      "Epoch [7/20] | Loss: 0.9345 | Train Acc: 67.24%\n",
      "Epoch [8/20] | Loss: 0.9103 | Train Acc: 67.95%\n",
      "Epoch [9/20] | Loss: 0.8903 | Train Acc: 68.74%\n",
      "Epoch [10/20] | Loss: 0.8706 | Train Acc: 69.45%\n",
      "Epoch [11/20] | Loss: 0.8542 | Train Acc: 70.27%\n",
      "Epoch [12/20] | Loss: 0.8330 | Train Acc: 70.83%\n",
      "Epoch [13/20] | Loss: 0.8245 | Train Acc: 71.40%\n",
      "Epoch [14/20] | Loss: 0.8065 | Train Acc: 71.92%\n",
      "Epoch [15/20] | Loss: 0.7985 | Train Acc: 72.39%\n",
      "Epoch [16/20] | Loss: 0.7890 | Train Acc: 72.48%\n",
      "Epoch [17/20] | Loss: 0.7770 | Train Acc: 72.96%\n",
      "Epoch [18/20] | Loss: 0.7718 | Train Acc: 73.25%\n",
      "Epoch [19/20] | Loss: 0.7569 | Train Acc: 73.72%\n",
      "Epoch [20/20] | Loss: 0.7432 | Train Acc: 74.28%\n",
      "\n",
      "✅ Test Accuracy: 77.58%\n",
      "⏱ Total Training Time: 4.97 mins\n"
     ]
    }
   ],
   "source": [
    "#One More Convolutional Layer\n",
    "class CNN_MoreConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MoreConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)  # one extra pool halves the size\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_MoreConv().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a6dc1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LessConv(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/20] | Loss: 1.7924 | Train Acc: 34.05%\n",
      "Epoch [2/20] | Loss: 1.6076 | Train Acc: 40.92%\n",
      "Epoch [3/20] | Loss: 1.5496 | Train Acc: 43.51%\n",
      "Epoch [4/20] | Loss: 1.5157 | Train Acc: 44.68%\n",
      "Epoch [5/20] | Loss: 1.4826 | Train Acc: 46.11%\n",
      "Epoch [6/20] | Loss: 1.4597 | Train Acc: 47.11%\n",
      "Epoch [7/20] | Loss: 1.4386 | Train Acc: 47.86%\n",
      "Epoch [8/20] | Loss: 1.4298 | Train Acc: 48.30%\n",
      "Epoch [9/20] | Loss: 1.4154 | Train Acc: 48.82%\n",
      "Epoch [10/20] | Loss: 1.3973 | Train Acc: 49.70%\n",
      "Epoch [11/20] | Loss: 1.3844 | Train Acc: 49.99%\n",
      "Epoch [12/20] | Loss: 1.3748 | Train Acc: 50.63%\n",
      "Epoch [13/20] | Loss: 1.3748 | Train Acc: 50.40%\n",
      "Epoch [14/20] | Loss: 1.3549 | Train Acc: 51.33%\n",
      "Epoch [15/20] | Loss: 1.3520 | Train Acc: 51.43%\n",
      "Epoch [16/20] | Loss: 1.3537 | Train Acc: 51.58%\n",
      "Epoch [17/20] | Loss: 1.3448 | Train Acc: 51.60%\n",
      "Epoch [18/20] | Loss: 1.3423 | Train Acc: 52.13%\n",
      "Epoch [19/20] | Loss: 1.3396 | Train Acc: 51.89%\n",
      "Epoch [20/20] | Loss: 1.3298 | Train Acc: 52.45%\n",
      "\n",
      "✅ Test Accuracy: 60.38%\n",
      "⏱ Total Training Time: 4.57 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_LessConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LessConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN_LessConv().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95eb86ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_BiggerKernel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/20] | Loss: 1.6756 | Train Acc: 38.75%\n",
      "Epoch [2/20] | Loss: 1.4044 | Train Acc: 49.19%\n",
      "Epoch [3/20] | Loss: 1.3103 | Train Acc: 53.11%\n",
      "Epoch [4/20] | Loss: 1.2583 | Train Acc: 54.90%\n",
      "Epoch [5/20] | Loss: 1.2217 | Train Acc: 56.29%\n",
      "Epoch [6/20] | Loss: 1.1891 | Train Acc: 57.75%\n",
      "Epoch [7/20] | Loss: 1.1633 | Train Acc: 58.73%\n",
      "Epoch [8/20] | Loss: 1.1418 | Train Acc: 59.69%\n",
      "Epoch [9/20] | Loss: 1.1256 | Train Acc: 60.21%\n",
      "Epoch [10/20] | Loss: 1.1055 | Train Acc: 60.91%\n",
      "Epoch [11/20] | Loss: 1.0906 | Train Acc: 61.53%\n",
      "Epoch [12/20] | Loss: 1.0777 | Train Acc: 62.10%\n",
      "Epoch [13/20] | Loss: 1.0656 | Train Acc: 62.45%\n",
      "Epoch [14/20] | Loss: 1.0530 | Train Acc: 62.75%\n",
      "Epoch [15/20] | Loss: 1.0459 | Train Acc: 63.32%\n",
      "Epoch [16/20] | Loss: 1.0274 | Train Acc: 64.01%\n",
      "Epoch [17/20] | Loss: 1.0296 | Train Acc: 63.80%\n",
      "Epoch [18/20] | Loss: 1.0205 | Train Acc: 64.02%\n",
      "Epoch [19/20] | Loss: 1.0105 | Train Acc: 64.56%\n",
      "Epoch [20/20] | Loss: 0.9989 | Train Acc: 65.05%\n",
      "\n",
      "✅ Test Accuracy: 69.69%\n",
      "⏱ Total Training Time: 5.20 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_BiggerKernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_BiggerKernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_BiggerKernel().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19cca05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_NoDropout(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/20] | Loss: 1.4885 | Train Acc: 46.00%\n",
      "Epoch [2/20] | Loss: 1.1341 | Train Acc: 59.51%\n",
      "Epoch [3/20] | Loss: 1.0170 | Train Acc: 63.76%\n",
      "Epoch [4/20] | Loss: 0.9430 | Train Acc: 66.76%\n",
      "Epoch [5/20] | Loss: 0.8878 | Train Acc: 68.63%\n",
      "Epoch [6/20] | Loss: 0.8450 | Train Acc: 70.20%\n",
      "Epoch [7/20] | Loss: 0.8065 | Train Acc: 71.62%\n",
      "Epoch [8/20] | Loss: 0.7705 | Train Acc: 72.62%\n",
      "Epoch [9/20] | Loss: 0.7465 | Train Acc: 73.89%\n",
      "Epoch [10/20] | Loss: 0.7288 | Train Acc: 74.48%\n",
      "Epoch [11/20] | Loss: 0.7093 | Train Acc: 75.33%\n",
      "Epoch [12/20] | Loss: 0.6944 | Train Acc: 75.67%\n",
      "Epoch [13/20] | Loss: 0.6751 | Train Acc: 76.28%\n",
      "Epoch [14/20] | Loss: 0.6603 | Train Acc: 76.79%\n",
      "Epoch [15/20] | Loss: 0.6538 | Train Acc: 77.25%\n",
      "Epoch [16/20] | Loss: 0.6391 | Train Acc: 77.71%\n",
      "Epoch [17/20] | Loss: 0.6242 | Train Acc: 78.30%\n",
      "Epoch [18/20] | Loss: 0.6145 | Train Acc: 78.53%\n",
      "Epoch [19/20] | Loss: 0.6064 | Train Acc: 78.85%\n",
      "Epoch [20/20] | Loss: 0.5930 | Train Acc: 79.19%\n",
      "\n",
      "✅ Test Accuracy: 75.78%\n",
      "⏱ Total Training Time: 4.50 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_NoDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_NoDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_NoDropout().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be86c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_AvgPool(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/20] | Loss: 1.6631 | Train Acc: 39.19%\n",
      "Epoch [2/20] | Loss: 1.4022 | Train Acc: 48.99%\n",
      "Epoch [3/20] | Loss: 1.2795 | Train Acc: 53.96%\n",
      "Epoch [4/20] | Loss: 1.2123 | Train Acc: 56.74%\n",
      "Epoch [5/20] | Loss: 1.1611 | Train Acc: 58.65%\n",
      "Epoch [6/20] | Loss: 1.1231 | Train Acc: 60.43%\n",
      "Epoch [7/20] | Loss: 1.0994 | Train Acc: 60.91%\n",
      "Epoch [8/20] | Loss: 1.0717 | Train Acc: 62.17%\n",
      "Epoch [9/20] | Loss: 1.0521 | Train Acc: 62.64%\n",
      "Epoch [10/20] | Loss: 1.0370 | Train Acc: 63.40%\n",
      "Epoch [11/20] | Loss: 1.0262 | Train Acc: 63.77%\n",
      "Epoch [12/20] | Loss: 1.0076 | Train Acc: 64.41%\n",
      "Epoch [13/20] | Loss: 0.9935 | Train Acc: 64.98%\n",
      "Epoch [14/20] | Loss: 0.9827 | Train Acc: 65.24%\n",
      "Epoch [15/20] | Loss: 0.9752 | Train Acc: 65.71%\n",
      "Epoch [16/20] | Loss: 0.9659 | Train Acc: 66.10%\n",
      "Epoch [17/20] | Loss: 0.9631 | Train Acc: 66.29%\n",
      "Epoch [18/20] | Loss: 0.9457 | Train Acc: 66.88%\n",
      "Epoch [19/20] | Loss: 0.9380 | Train Acc: 67.20%\n",
      "Epoch [20/20] | Loss: 0.9302 | Train Acc: 67.47%\n",
      "\n",
      "✅ Test Accuracy: 70.69%\n",
      "⏱ Total Training Time: 5.02 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_AvgPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_AvgPool, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AvgPool2d(2, 2)  # changed pooling\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_AvgPool().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3857e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_MorePooling(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=4096, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Epoch [1/20] | Loss: 1.6657 | Train Acc: 38.76%\n",
      "Epoch [2/20] | Loss: 1.4051 | Train Acc: 49.20%\n",
      "Epoch [3/20] | Loss: 1.2895 | Train Acc: 53.54%\n",
      "Epoch [4/20] | Loss: 1.2132 | Train Acc: 56.72%\n",
      "Epoch [5/20] | Loss: 1.1719 | Train Acc: 58.13%\n",
      "Epoch [6/20] | Loss: 1.1354 | Train Acc: 59.71%\n",
      "Epoch [7/20] | Loss: 1.1038 | Train Acc: 60.88%\n",
      "Epoch [8/20] | Loss: 1.0794 | Train Acc: 61.70%\n",
      "Epoch [9/20] | Loss: 1.0565 | Train Acc: 62.78%\n",
      "Epoch [10/20] | Loss: 1.0504 | Train Acc: 63.13%\n",
      "Epoch [11/20] | Loss: 1.0270 | Train Acc: 63.55%\n",
      "Epoch [12/20] | Loss: 1.0145 | Train Acc: 64.32%\n",
      "Epoch [13/20] | Loss: 1.0083 | Train Acc: 64.77%\n",
      "Epoch [14/20] | Loss: 0.9900 | Train Acc: 65.07%\n",
      "Epoch [15/20] | Loss: 0.9770 | Train Acc: 65.75%\n",
      "Epoch [16/20] | Loss: 0.9768 | Train Acc: 65.78%\n",
      "Epoch [17/20] | Loss: 0.9660 | Train Acc: 66.26%\n",
      "Epoch [18/20] | Loss: 0.9588 | Train Acc: 66.23%\n",
      "Epoch [19/20] | Loss: 0.9532 | Train Acc: 66.56%\n",
      "Epoch [20/20] | Loss: 0.9453 | Train Acc: 66.72%\n",
      "\n",
      "✅ Test Accuracy: 72.22%\n",
      "⏱ Total Training Time: 4.72 mins\n"
     ]
    }
   ],
   "source": [
    "class CNN_MorePooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MorePooling, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # smaller spatial size after extra pooling\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # first pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))   # second pooling\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_MorePooling().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf71e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_MorePooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_MorePooling, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # smaller spatial size after extra pooling\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # first pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))   # second pooling\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CNN_MorePooling().to(device)\n",
    "print(model)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Define loss and optimizer\n",
    "# ------------------------------------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Training loop\n",
    "# ------------------------------------------------------------\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluation on test data\n",
    "# ------------------------------------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"⏱ Total Training Time: {(time.time() - start_time)/60:.2f} mins\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
